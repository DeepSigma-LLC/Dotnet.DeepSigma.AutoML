
namespace DeepSigma.AutoML.Enums.Evaluation;

/// <summary>
/// NLPMetric specifies the various metrics used to evaluate the performance of natural language processing (NLP) models, which are a type of machine learning model that processes and analyzes human language data to perform tasks such as text classification, sentiment analysis, machine translation, and text generation.
/// </summary>
public enum NLPMetric
{
    /// <summary>
    /// BLEU (Bilingual Evaluation Understudy) is a widely used metric for evaluating the quality of machine-generated translations by comparing them to reference translations created by humans, which measures the overlap of n-grams between the generated and reference translations.
    /// Higher BLEU scores indicating better translation quality and lower scores indicating poorer performance, and is particularly useful for assessing the fluency and adequacy of machine-generated translations in natural language processing tasks such as machine translation and text generation.
    /// </summary>
    BlEU,
    /// <summary>
    /// Perplexity is a commonly used metric for evaluating the performance of language models, which measures how well a language model predicts a given text by calculating the average negative log-likelihood of the predicted tokens. 
    /// Lower perplexity indicating better performance and higher perplexity indicating poorer performance, and is particularly useful for assessing the model's ability to generate coherent and fluent text in natural language processing tasks such as language modeling and text generation.
    /// </summary>
    Perplexity,
    /// <summary>
    /// Recall-Oriented Understudy for Gisting Evaluation (ROUGE) is a set of metrics used to evaluate the quality of summaries generated by NLP models by comparing the generated summaries to reference summaries created by humans, and measuring the overlap of n-grams, word sequences, and word pairs between the generated and reference summaries to assess the quality and relevance of the generated content.
    /// </summary>
    RecallOrientedUnderstudyForGistingEvaluation,
}
